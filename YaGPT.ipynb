{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46d4d755-c1d5-453f-9bbd-f670ad933c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('input.txt', 'r') as input_file:\n",
    "    text = input_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6ac2bb3-b213-4d07-9844-892f65c8b1bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "unique_chars = sorted(list(set(text)))\n",
    "vocab_size = len(unique_chars)\n",
    "print(''.join(unique_chars))\n",
    "print(len(unique_chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c69da69d-cde1-4ce7-a75e-5cd41bf5a6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46, 43, 50, 50, 53]\n",
      "hello\n"
     ]
    }
   ],
   "source": [
    "ctoi = { char:ind for ind,char in enumerate(unique_chars)}\n",
    "itoc = {ind:char for ind,char in enumerate(unique_chars)}\n",
    "\n",
    "encode = lambda s: [ctoi[z] for z in s]\n",
    "decode = lambda i: ''.join(itoc[z] for z in i)\n",
    "\n",
    "print(encode('hello'))\n",
    "print(decode(encode('hello')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d042f4fb-2bbd-4c19-be06-4dbb28996a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92c3c4ad-32a0-4830-b3ca-12caf57dc52e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
       "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
       "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
       "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
       "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
       "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.tensor(encode(text), dtype = torch.long)\n",
    "data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63618755-c61b-4afc-8ff7-a9da965d4d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and test split. we are considering 90% of the data as our training data.\n",
    "\n",
    "factor = int(0.9 * len(data))\n",
    "train = data[:factor]\n",
    "val = data[factor:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fde04bb-7f00-4c0d-81ed-f21913dd023f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([18, 47, 56, 57, 58,  1, 15, 47]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "blk = 8\n",
    "print(train[:blk],'\\n')\n",
    "\n",
    "def get_targets(mat, tar, block_size):\n",
    "    for _ in range(block_size):\n",
    "        context = mat[:_+1]\n",
    "        target = tar[_]\n",
    "        print(f'context:{context}',f'target: {target}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97581f65-b08e-40ff-964e-64bb0f007498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 8]),\n",
       " torch.Size([4, 8]),\n",
       " tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
       "         [44, 53, 56,  1, 58, 46, 39, 58],\n",
       "         [52, 58,  1, 58, 46, 39, 58,  1],\n",
       "         [25, 17, 27, 10,  0, 21,  1, 54]]),\n",
       " tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
       "         [53, 56,  1, 58, 46, 39, 58,  1],\n",
       "         [58,  1, 58, 46, 39, 58,  1, 46],\n",
       "         [17, 27, 10,  0, 21,  1, 54, 39]]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size = 4\n",
    "blk_size = 8\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train if split == 'train' else val\n",
    "    indices = torch.randint((len(data) - blk_size), (batch_size,))\n",
    "    x = torch.stack([data[i:i+blk_size] for i in indices])\n",
    "    y = torch.stack([data[i+1:i+blk_size+1] for i in indices])\n",
    "    x,y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "x,y = get_batch('train')\n",
    "\n",
    "x.shape,y.shape,x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc036ebf-5727-4409-848a-6525af48aed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context:tensor([24]) target: 43\n",
      "\n",
      "context:tensor([24, 43]) target: 58\n",
      "\n",
      "context:tensor([24, 43, 58]) target: 5\n",
      "\n",
      "context:tensor([24, 43, 58,  5]) target: 57\n",
      "\n",
      "context:tensor([24, 43, 58,  5, 57]) target: 1\n",
      "\n",
      "context:tensor([24, 43, 58,  5, 57,  1]) target: 46\n",
      "\n",
      "context:tensor([24, 43, 58,  5, 57,  1, 46]) target: 43\n",
      "\n",
      "context:tensor([24, 43, 58,  5, 57,  1, 46, 43]) target: 39\n",
      "\n",
      "context:tensor([44]) target: 53\n",
      "\n",
      "context:tensor([44, 53]) target: 56\n",
      "\n",
      "context:tensor([44, 53, 56]) target: 1\n",
      "\n",
      "context:tensor([44, 53, 56,  1]) target: 58\n",
      "\n",
      "context:tensor([44, 53, 56,  1, 58]) target: 46\n",
      "\n",
      "context:tensor([44, 53, 56,  1, 58, 46]) target: 39\n",
      "\n",
      "context:tensor([44, 53, 56,  1, 58, 46, 39]) target: 58\n",
      "\n",
      "context:tensor([44, 53, 56,  1, 58, 46, 39, 58]) target: 1\n",
      "\n",
      "context:tensor([52]) target: 58\n",
      "\n",
      "context:tensor([52, 58]) target: 1\n",
      "\n",
      "context:tensor([52, 58,  1]) target: 58\n",
      "\n",
      "context:tensor([52, 58,  1, 58]) target: 46\n",
      "\n",
      "context:tensor([52, 58,  1, 58, 46]) target: 39\n",
      "\n",
      "context:tensor([52, 58,  1, 58, 46, 39]) target: 58\n",
      "\n",
      "context:tensor([52, 58,  1, 58, 46, 39, 58]) target: 1\n",
      "\n",
      "context:tensor([52, 58,  1, 58, 46, 39, 58,  1]) target: 46\n",
      "\n",
      "context:tensor([25]) target: 17\n",
      "\n",
      "context:tensor([25, 17]) target: 27\n",
      "\n",
      "context:tensor([25, 17, 27]) target: 10\n",
      "\n",
      "context:tensor([25, 17, 27, 10]) target: 0\n",
      "\n",
      "context:tensor([25, 17, 27, 10,  0]) target: 21\n",
      "\n",
      "context:tensor([25, 17, 27, 10,  0, 21]) target: 1\n",
      "\n",
      "context:tensor([25, 17, 27, 10,  0, 21,  1]) target: 54\n",
      "\n",
      "context:tensor([25, 17, 27, 10,  0, 21,  1, 54]) target: 39\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in range(batch_size):\n",
    "    get_targets(x[_],y[_],len(x[_]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "841b241d-4572-4839-accd-89338e097855",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn import functional as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4cea2d69-dba3-41cd-9bb2-c5557c315908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0, 31, 23, 21]])\n",
      "\n",
      "JMT\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "\n",
    "class BigramModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.embedding_table = nn.Embedding(vocab_size,vocab_size)\n",
    "        \n",
    "    def forward(self, idx, targets=None):\n",
    "        logits = self.embedding_table(idx)\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else :\n",
    "            B,T,C = logits.shape\n",
    "            logits = logits.view(B*T,C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = f.cross_entropy(logits,targets)\n",
    "            \n",
    "        return loss,logits\n",
    "\n",
    "    def generate(self, idx, max_tokens):\n",
    "        for _ in range(max_tokens):\n",
    "            loss,logits = self(idx)\n",
    "            logits = logits[:,-1,:]  \n",
    "            probs = f.softmax(logits, dim = 1)          \n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            idx = torch.cat((idx,idx_next), dim = 1)\n",
    "        return idx\n",
    "\n",
    "model = BigramModel(vocab_size)\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "loss,logits.shape\n",
    "idx = torch.zeros((1,1), dtype = torch.long, device = device)\n",
    "print(model.generate(idx,max_tokens=3))\n",
    "print(decode(model.generate(idx,max_tokens=3)[0].tolist()))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d27c018d-09fd-493f-b157-3051e3c482aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5a2878e2-d7d4-47b3-8586-8fa60a0cad9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5881810188293457\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32;\n",
    "\n",
    "for _ in range(10000):\n",
    "    x,y = get_batch('train')\n",
    "    loss,logits = model(x,y)\n",
    "    \n",
    "    optimizer.zero_grad(set_to_none = True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "eccca093-0106-4fb8-bfc5-7d55666ed7e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1808, -0.0700],\n",
       "         [-0.3596, -0.9152],\n",
       "         [ 0.6258,  0.0255],\n",
       "         [ 0.9545,  0.0643],\n",
       "         [ 0.3612,  1.1679],\n",
       "         [-1.3499, -0.5102],\n",
       "         [ 0.2360, -0.2398],\n",
       "         [-0.9211,  1.5433]],\n",
       "\n",
       "        [[ 1.3488, -0.1396],\n",
       "         [ 0.2858,  0.9651],\n",
       "         [-2.0371,  0.4931],\n",
       "         [ 1.4870,  0.5910],\n",
       "         [ 0.1260, -1.5627],\n",
       "         [-1.1601, -0.3348],\n",
       "         [ 0.4478, -0.8016],\n",
       "         [ 1.5236,  2.5086]],\n",
       "\n",
       "        [[-0.6631, -0.2513],\n",
       "         [ 1.0101,  0.1215],\n",
       "         [ 0.1584,  1.1340],\n",
       "         [-1.1539, -0.2984],\n",
       "         [-0.5075, -0.9239],\n",
       "         [ 0.5467, -1.4948],\n",
       "         [-1.2057,  0.5718],\n",
       "         [-0.5974, -0.6937]],\n",
       "\n",
       "        [[ 1.6455, -0.8030],\n",
       "         [ 1.3514, -0.2759],\n",
       "         [-1.5108,  2.1048],\n",
       "         [ 2.7630, -1.7465],\n",
       "         [ 1.4516, -1.5103],\n",
       "         [ 0.8212, -0.2115],\n",
       "         [ 0.7789,  1.5333],\n",
       "         [ 1.6097, -0.4032]]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "a,b,c = 4,8,2\n",
    "x = torch.randn(a,b,c)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "68de291a-10a6-4791-bb76-552be7b14621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1808, -0.0700],\n",
       "        [-0.0894, -0.4926],\n",
       "        [ 0.1490, -0.3199],\n",
       "        [ 0.3504, -0.2238],\n",
       "        [ 0.3525,  0.0545],\n",
       "        [ 0.0688, -0.0396],\n",
       "        [ 0.0927, -0.0682],\n",
       "        [-0.0341,  0.1332]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#brute force\n",
    "res1 = torch.zeros(a,b,c)\n",
    "for row in range(a):\n",
    "    for col in range(b):\n",
    "        prev = x[row,:col+1]\n",
    "        mean = torch.mean(prev, dim = 0)\n",
    "        res1[row,col] = mean\n",
    "res1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8561ea1c-738e-456f-a225-69978b282918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1808, -0.0700],\n",
       "        [-0.0894, -0.4926],\n",
       "        [ 0.1490, -0.3199],\n",
       "        [ 0.3504, -0.2238],\n",
       "        [ 0.3525,  0.0545],\n",
       "        [ 0.0688, -0.0396],\n",
       "        [ 0.0927, -0.0682],\n",
       "        [-0.0341,  0.1332]])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vectorized\n",
    "tril = torch.tril(torch.ones(b,b))\n",
    "t = tril/torch.sum(tril,dim = 1,keepdims = True)\n",
    "res2  = t@x\n",
    "res2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "647ba000-a2e7-44ad-821e-a1ded31d7f8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(res1,res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "156b85e3-b7f6-411c-ad5d-e109e7060c4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alternative approach used in soft attention\n",
    "\n",
    "z = torch.zeros((b,b))\n",
    "z = z.masked_fill(tril == 0, float('-inf'))\n",
    "soft_max = f.softmax(z,dim = 1)\n",
    "res3 = soft_max @ x\n",
    "\n",
    "torch.allclose(res2,res3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88e85bc-161b-4288-b549-2643b2f777d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
